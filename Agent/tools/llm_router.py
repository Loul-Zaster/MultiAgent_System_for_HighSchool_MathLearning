import os
import json
import asyncio
from typing import Dict, List, Optional
from dataclasses import dataclass
from groq import Groq

# =================== Configuration ===================
try:
    from dotenv import load_dotenv
    # Load from project root
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
    load_dotenv(dotenv_path=os.path.join(project_root, ".env"))
except Exception as e:
    print(f"âš ï¸ Could not load .env: {e}")
    pass

GROQ_API_KEY = os.getenv("GROQ_API_KEY")
groq_client: Optional[Groq] = None
if GROQ_API_KEY:
    try:
        groq_client = Groq(api_key=GROQ_API_KEY)
    except Exception as e:
        print(f"âš ï¸ Failed to initialize Groq client in LLM router: {e}")
        groq_client = None
else:
    groq_client = None

# =================== Data Structures ===================
@dataclass
class AgentInfo:
    name: str
    description: str
    capabilities: List[str]
    examples: List[str]

@dataclass
class RoutingDecision:
    agent_type: str
    confidence: float
    reasoning: str
    alternative_agents: List[Dict[str, any]]

# =================== LLM Router ===================
class LLMRouter:
    def __init__(self):
        self.agents = self._initialize_agents()
    
    def _initialize_agents(self) -> Dict[str, AgentInfo]:
        """Define available agents with their capabilities"""
        return {
            "math": AgentInfo(
                name="Math Agent",
                description="ChuyÃªn giáº£i toÃ¡n, phÆ°Æ¡ng trÃ¬nh, tÃ­nh toÃ¡n, phÃ¢n tÃ­ch sá»‘ liá»‡u vÃ  cÃ¡c bÃ i toÃ¡n toÃ¡n há»c",
                capabilities=[
                    "Giáº£i phÆ°Æ¡ng trÃ¬nh Ä‘áº¡i sá»‘ vÃ  vi phÃ¢n",
                    "TÃ­nh toÃ¡n sá»‘ há»c vÃ  Ä‘áº¡i sá»‘",
                    "PhÃ¢n tÃ­ch thá»‘ng kÃª vÃ  xÃ¡c suáº¥t",
                    "Váº½ Ä‘á»“ thá»‹ hÃ m sá»‘",
                    "Giáº£i há»‡ phÆ°Æ¡ng trÃ¬nh tuyáº¿n tÃ­nh",
                    "TÃ­nh toÃ¡n ma tráº­n vÃ  vector",
                    "Giáº£i tÃ­ch vÃ  Ä‘áº¡o hÃ m",
                    "HÃ¬nh há»c vÃ  khÃ´ng gian"
                ],
                examples=[
                    "Giáº£i phÆ°Æ¡ng trÃ¬nh x^2 - 5x + 6 = 0",
                    "TÃ­nh Ä‘áº¡o hÃ m cá»§a f(x) = x^3 + 2x^2 - 5x + 1",
                    "TÃ¬m ma tráº­n nghá»‹ch Ä‘áº£o cá»§a A = [[1,2],[3,4]]",
                    "Váº½ Ä‘á»“ thá»‹ hÃ m sá»‘ y = sin(x)",
                    "TÃ­nh xÃ¡c suáº¥t cá»§a biáº¿n cá»‘ ngáº«u nhiÃªn",
                    "Giáº£i há»‡ phÆ°Æ¡ng trÃ¬nh tuyáº¿n tÃ­nh 3 áº©n"
                ]
            ),
            "research": AgentInfo(
                name="Research Agent", 
                description="NghiÃªn cá»©u, tÃ¬m kiáº¿m thÃ´ng tin realtime, phÃ¢n tÃ­ch dá»¯ liá»‡u vÃ  tá»•ng há»£p bÃ¡o cÃ¡o",
                capabilities=[
                    "TÃ¬m kiáº¿m thÃ´ng tin realtime trÃªn web",
                    "PhÃ¢n tÃ­ch xu hÆ°á»›ng vÃ  thá»‘ng kÃª",
                    "Tá»•ng há»£p bÃ¡o cÃ¡o tá»« nhiá»u nguá»“n",
                    "Cáº­p nháº­t tin tá»©c má»›i nháº¥t",
                    "NghiÃªn cá»©u thá»‹ trÆ°á»ng vÃ  kinh táº¿",
                    "PhÃ¢n tÃ­ch dá»¯ liá»‡u vÃ  biá»ƒu Ä‘á»“",
                    "So sÃ¡nh vÃ  Ä‘Ã¡nh giÃ¡ thÃ´ng tin"
                ],
                examples=[
                    "Tin tá»©c má»›i nháº¥t vá» AI tuáº§n nÃ y",
                    "PhÃ¢n tÃ­ch xu hÆ°á»›ng thá»‹ trÆ°á»ng chá»©ng khoÃ¡n",
                    "TÃ¬m hiá»ƒu vá» cÃ´ng nghá»‡ blockchain",
                    "BÃ¡o cÃ¡o vá» tÃ¬nh hÃ¬nh kinh táº¿ Viá»‡t Nam",
                    "NghiÃªn cá»©u vá» biáº¿n Ä‘á»•i khÃ­ háº­u",
                    "So sÃ¡nh cÃ¡c framework JavaScript"
                ]
            ),
            "ocr": AgentInfo(
                name="OCR Agent",
                description="Xá»­ lÃ½ áº£nh, nháº­n dáº¡ng vÄƒn báº£n, OCR vÃ  chuyá»ƒn Ä‘á»•i tÃ i liá»‡u",
                capabilities=[
                    "Nháº­n dáº¡ng vÄƒn báº£n tá»« áº£nh (OCR)",
                    "Xá»­ lÃ½ vÃ  phÃ¢n tÃ­ch hÃ¬nh áº£nh",
                    "Chuyá»ƒn Ä‘á»•i tÃ i liá»‡u PDF thÃ nh text",
                    "Nháº­n dáº¡ng kÃ½ tá»± vÃ  báº£ng biá»ƒu",
                    "Extract text tá»« file áº£nh",
                    "Scan vÃ  Ä‘á»c ná»™i dung tÃ i liá»‡u",
                    "Xá»­ lÃ½ áº£nh vá»›i nhiá»u Ä‘á»‹nh dáº¡ng"
                ],
                examples=[
                    "Xá»­ lÃ½ áº£nh nÃ y báº±ng OCR",
                    "Chuyá»ƒn Ä‘á»•i tÃ i liá»‡u PDF thÃ nh text",
                    "Nháº­n dáº¡ng vÄƒn báº£n trong hÃ¬nh áº£nh",
                    "Scan vÃ  Ä‘á»c ná»™i dung báº£ng biá»ƒu",
                    "Extract text tá»« file áº£nh",
                    "Xá»­ lÃ½ áº£nh chá»©a cÃ´ng thá»©c toÃ¡n"
                ]
            ),
            "general": AgentInfo(
                name="General Agent",
                description="Trá»£ lÃ½ tá»•ng quÃ¡t, tráº£ lá»i cÃ¢u há»i, tÆ° váº¥n, há»— trá»£ vÃ  láº­p trÃ¬nh",
                capabilities=[
                    "Tráº£ lá»i cÃ¢u há»i tá»•ng quÃ¡t",
                    "TÆ° váº¥n vÃ  Ä‘Æ°a ra gá»£i Ã½",
                    "HÆ°á»›ng dáº«n vÃ  giáº£i thÃ­ch",
                    "So sÃ¡nh vÃ  phÃ¢n tÃ­ch",
                    "Há»— trá»£ láº­p trÃ¬nh vÃ  code",
                    "Debug vÃ  sá»­a lá»—i",
                    "Viáº¿t function vÃ  táº¡o API",
                    "PhÃ¡t triá»ƒn pháº§n má»m"
                ],
                examples=[
                    "HÃ´m nay lÃ  ngÃ y gÃ¬?",
                    "Giáº£i thÃ­ch vá» machine learning",
                    "So sÃ¡nh iPhone vÃ  Samsung",
                    "HÆ°á»›ng dáº«n náº¥u phá»Ÿ",
                    "LÃ m sao viáº¿t function Python?",
                    "CÃ¡ch debug lá»—i JavaScript",
                    "Táº¡o API REST vá»›i Flask",
                    "TÆ° váº¥n chá»n laptop"
                ]
            )
        }
    
    async def _get_llm_routing_decision(self, prompt: str) -> Dict[str, any]:
        """Use Groq LLM to make intelligent routing decision"""
        if not groq_client:
            return {
                "agent": "general",
                "confidence": 0.5,
                "reasoning": "GROQ khÃ´ng kháº£ dá»¥ng, chá»n general agent",
                "alternatives": []
            }
        
        try:
            # Create agent descriptions for LLM
            agents_desc = ""
            for agent_name, agent_info in self.agents.items():
                agents_desc += f"""
**{agent_info.name}** ({agent_name}):
- MÃ´ táº£: {agent_info.description}
- Kháº£ nÄƒng: {', '.join(agent_info.capabilities[:3])}...
- VÃ­ dá»¥: {', '.join(agent_info.examples[:2])}

"""
            
            routing_prompt = f"""Báº¡n lÃ  má»™t há»‡ thá»‘ng routing thÃ´ng minh. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  chá»n agent phÃ¹ há»£p nháº¥t Ä‘á»ƒ xá»­ lÃ½ cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng.

CÃ¡c agent cÃ³ sáºµn:
{agents_desc}

CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng: "{prompt}"

HÃ£y phÃ¢n tÃ­ch vÃ  tráº£ lá»i theo Ä‘á»‹nh dáº¡ng JSON sau:
{{
    "agent": "tÃªn_agent_Ä‘Æ°á»£c_chá»n (math/research/ocr/general)",
    "confidence": sá»‘_tá»«_0_Ä‘áº¿n_1,
    "reasoning": "lÃ½ do chi tiáº¿t táº¡i sao chá»n agent nÃ y",
    "alternatives": [
        {{"agent": "tÃªn_agent", "confidence": sá»‘_tá»«_0_Ä‘áº¿n_1, "reason": "lÃ½ do"}},
        ...
    ]
}}

Quy táº¯c chá»n agent:
- math: CÃ¢u há»i vá» toÃ¡n há»c, phÆ°Æ¡ng trÃ¬nh, tÃ­nh toÃ¡n, thá»‘ng kÃª
- research: CÃ¢u há»i cáº§n tÃ¬m kiáº¿m thÃ´ng tin má»›i, nghiÃªn cá»©u, tin tá»©c
- ocr: YÃªu cáº§u xá»­ lÃ½ áº£nh, nháº­n dáº¡ng vÄƒn báº£n, OCR
- general: CÃ¢u há»i tá»•ng quÃ¡t, láº­p trÃ¬nh, tÆ° váº¥n, hÆ°á»›ng dáº«n

HÃ£y phÃ¢n tÃ­ch ká»¹ vÃ  chá»n chÃ­nh xÃ¡c nháº¥t cÃ³ thá»ƒ."""
            
            completion = groq_client.chat.completions.create(
                model="openai/gpt-oss-20b",
                messages=[{"role": "user", "content": routing_prompt}],
                temperature=0.1,  # Low temperature for consistent routing
                max_completion_tokens=500
            )
            
            response = completion.choices[0].message.content or "{}"
            
            # Clean response - remove any markdown formatting
            response = response.strip()
            if response.startswith("```json"):
                response = response[7:]
            if response.endswith("```"):
                response = response[:-3]
            response = response.strip()
            
            # Fix escape characters
            response = response.replace("\\(", "(").replace("\\)", ")")
            
            print(f"ğŸ” LLM Response: {response}")  # Debug
            
            result = json.loads(response)
            
            # Validate and ensure required fields
            if "agent" not in result:
                result["agent"] = "general"
            if "confidence" not in result:
                result["confidence"] = 0.5
            if "reasoning" not in result:
                result["reasoning"] = "KhÃ´ng cÃ³ lÃ½ do Ä‘Æ°á»£c cung cáº¥p"
            if "alternatives" not in result:
                result["alternatives"] = []
            
            return result
            
        except Exception as e:
            print(f"âš ï¸ LLM routing error: {e}")
            return {
                "agent": "general",
                "confidence": 0.3,
                "reasoning": f"Lá»—i LLM routing: {str(e)}",
                "alternatives": []
            }
    
    async def route(self, prompt: str) -> RoutingDecision:
        """Main routing method using LLM"""
        # Get LLM routing decision
        llm_decision = await self._get_llm_routing_decision(prompt)
        
        # Validate agent exists
        chosen_agent = llm_decision["agent"]
        if chosen_agent not in self.agents:
            chosen_agent = "general"
            llm_decision["confidence"] = 0.3
            llm_decision["reasoning"] = f"Agent '{llm_decision['agent']}' khÃ´ng tá»“n táº¡i, chá»n general"
        
        # Format alternatives
        alternatives = []
        for alt in llm_decision.get("alternatives", []):
            if alt.get("agent") in self.agents:
                alternatives.append({
                    "agent": alt["agent"],
                    "confidence": alt.get("confidence", 0.0),
                    "reason": alt.get("reason", "KhÃ´ng cÃ³ lÃ½ do")
                })
        
        return RoutingDecision(
            agent_type=chosen_agent,
            confidence=llm_decision["confidence"],
            reasoning=llm_decision["reasoning"],
            alternative_agents=alternatives
        )

# =================== Usage ===================
async def route_prompt(prompt: str) -> RoutingDecision:
    """Convenience function to route a prompt using LLM"""
    router = LLMRouter()
    return await router.route(prompt)

# =================== Testing ===================
async def test_llm_router():
    """Test function for LLM router"""
    test_prompts = [
        "Giáº£i phÆ°Æ¡ng trÃ¬nh x^2 - 5x + 6 = 0",
        "TÃ¬m hiá»ƒu vá» machine learning",
        "Xá»­ lÃ½ áº£nh nÃ y báº±ng OCR",
        "LÃ m sao viáº¿t function Python?",
        "Tin tá»©c má»›i nháº¥t vá» AI"
    ]
    
    router = LLMRouter()
    
    print("ğŸ§ª Testing LLM Router...")
    print("=" * 60)
    
    for prompt in test_prompts:
        decision = await router.route(prompt)
        print(f"ğŸ“ Prompt: {prompt}")
        print(f"ğŸ¯ Agent: {decision.agent_type}")
        print(f"ğŸ“Š Confidence: {decision.confidence:.2f}")
        print(f"ğŸ’­ Reasoning: {decision.reasoning}")
        if decision.alternative_agents:
            print(f"ğŸ”„ Alternatives: {[alt['agent'] for alt in decision.alternative_agents]}")
        print("-" * 40)

if __name__ == "__main__":
    asyncio.run(test_llm_router())
